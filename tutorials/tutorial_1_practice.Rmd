Tutorial paper: doi: 10.1111/2041-210X.12263

# 1. Generating PyRate.py Input File (2 Methods)

## 1.A. CSV From Outside Source

**Loading the file** our functions will come from

```{r}
source("../pyrate_utilities.r")
```

**Download fossil occurrences** for a clade from the [Paleobiology Database](https://paleobiodb.org/classic/displayDownloadGenerator). E.g. search for the genus *Canis*

-   Check the box "Show accepted names only" in the "Select by taxonomy" section
-   Uncheck the box "Include metadata at the beginning of the output" in the "Choose output options" section. - Save it as a cvs file, e.g. using the file name *Canis_pbdb_data.csv*.

**Defining a vector** of extant (still alive) species from all the species in the data

```{r}
extant_dogs = c("Canis rufus","Canis lupus","Canis aureus","Canis latrans","Canis mesomelas","Canis anthus","Pseudalopex gymnocercus","Canis adustus","Canis familiaris")
```

**Parse raw PBDB data with extract.ages.pbdb() → generate 3 files:**

```{r}
extract.ages.pbdb(file = "../example_files/Canis_example/Canis_pbdb_data.csv", extant_species = extant_dogs)
```

-   **Replicates**: The `replicates` argument specifies the number of times the age range (min and max) of each fossil occurrence should be resampled. Resampling = when the function creates that n number of datasets, in each dataset it will select a random age range for each species from within that species' original age range. Setting `replicates = 10` will generate 10 replicated datasets in the PyRate input file, each with different age ranges selected for each species. Then in the downstream PyRate analysis, you can analyze each dataset separately, and the combined results will account for age uncertainties in the fossil record.

    -   So if a fossil occurrence has a min age of 10 Ma and a max age of 12 Ma, and `replicates=10` is specified, the function will generate 10 replicated datasets where the age of that fossil occurrence is randomly sampled between 10 Ma and 12 Ma for each of the 10 replicates.

-   **Random**: The `random` argument is set to `TRUE` by default, which means that the resampling of ages will be done randomly within the specified temporal ranges.

-   **Cutoff**: The `cutoff` argument can be used to remove fossil occurrences with an age range greater than the range you specify (in millions of years). For example, setting `cutoff = 10` will remove all occurrences where the difference between the maximum and minimum age is larger than 10 million years.

**3 Output Files:**

\* = name of the dataset

1.  **\*.txt** = dataset as a .txt
    1.  Then the function passes the .txt to the **extract.ages()** function, which creates the following two files
2.  **\*\_TaxonList.txt** = list of species in the dataset and their status (extinct vs. extant). This is created because the **extract.ages()** function has the argument 'save_tax_list' set to TRUE by default
3.  **\*\_PyRate.py** = PyRate formatted input, with the specified number of replicated datasets (if replicates 'argument' was used)
    1.  \*See "**example_files/Canis_example/PyRate_input_txt_visualized.png**"
    2.  In the resultant file, there is a list of arrays containing a list of numbers. The list is one PyRate input dataset, parsed form the raw data. In this example there is only one list because we didn't specify any replicated data (replicates argument below)
    3.  Each array represents one taxon (species)
    4.  Each value in the array represents one fossil occurrence. Each value is a **randomly sampled age (in mills of years) of the fossil occurrence for** **that taxon/array. Longer arrays = more occurrences of a fossil of that species, so more ages**
    5.  The taxa_names variables at the end of the file = the order of the arrays
    6.  If a taxon is extant (still alive), the last value in its array is = 0 to represent the present day

### 1.A.i. TERMINAL: data summary on the \*\_PyRate.py file

**Start in the PyRate Directory** (parent). This command will generate summary statistics for the dataset

1.  And save those off as a **.txt file** with a name of your choosing. The .txt can be used in a dataframe later

`python PyRate.py 'example_files/Canis_example/Canis_pbdb_data_PyRate.py' -data_info | tee path/tutorial_1_data_summary.txt`

## 1.B. CSV Created by Hand

**Prepare a fossil occurrence table** **in .txt format** with 4 columns: Taxon name, Status (extinct or extant), Minimum age, and Maximum age. An additional column can be included for a trait value (e.g., body mass)

**Loading the file** our functions will come from

```{r}
source("../pyrate_utilities.r")
```

**Parse the raw data with extract.ages() –\> generate 2 files:**

1.  **\*\_PyRate.py:** PyRate input file!
2.  **\*\_TaxonList.txt:** List of species names

```{r}
extract.ages(file="../PyRate/example_files/Ursidae.txt", replicates=10)
```

'**Replicates**', '**cutoff**' arguments available in this function too.

## 1.C. Input Dataset with a "Site" Column

If your data contains info on which site a fossil came from, and some fossils were found at the same site, we will randomize the ages by the common site, NOT by each fossil occurrence individually.

I.e., earlier we said extract.ages() and extract.ages.pbdb() (functions for parsing the raw data) would –\> PyRate.py input file where each fossil's age was a random sample taken from within their individual, unique temporal age range (min_age to max_age).

Now, we're saying that if we have data that specifies which site a fossil came from (a site column), and fossils share sites, we will instead assign each fossil occurrence an age that is a random sample of the SITE's unique temporal range. We'll average the min and max ages of all the fossils occurring at the same site, randomly sample within that, then assign EVERY fossil that occurred at that site the same age. So every fossil found at Site A will have the same randomly sampled age. Process:

1.  The average minimum age and maximum age of all fossils found in Site A will be calculated, and assigned as the temporal range for Site A, called 'mimima_1' and 'maxima_1' respectively
2.  The function runif() will randomly select an age from within each Site's range 'mimima_1' to 'maxima_1', round it to 6 decimal places, and store it as a new column (new entry in each array in \*\_PyRate.py) '**new**\_**age**'
3.  The resultant \*\_PyRate.py file will look the same as "**example_files/Canis_example/PyRate_input_txt_visualized.png**" except that each array (taxon/species) will only have a maximum of two values:
    1.  One value corresponding to its site's randomly sampled age.
    2.  A 0 value at the end of the array, if it's an extant species (discussed previously)

## 1.D. Check \*\_TaxonList.txt for Species Name Typos

**\*Any command involving PyRate.py calls that PyRate file, which means we need to be in the master directory of PyRate (the parent folder containing PyRate.py**

**TERMINAL** command:

`python PyRate.py -check_names path/*_TaxonList.txt`

**Output: \*\_TaxonList\_**scores

This will return a table ranking possible typos. You should check these yourself to see if they are errors. If they are, go back to the dataset, fix it, and re-run the needed steps above.

-   Ranks 0-1 = possible misspellings

-   Ranks 2-3 = possibly different names

# 2. Estimating S + E W/ Preservation Models

## 2.A. Defining the Preservation Model Type in TERMINAL. For later use in Section 3.

Epoch = a predefined time interval. Can be based on geological, environmental, etc. criteria. Set by the user in PyRate.

**Types of Models:** \*See Preservation_Models_Visualizations.png in tutorials folder

-   NHPP, HPP, TPP models assume all lineages have the same preservation rate

    -   All lineages have equal chances of being preserved in the fossil record

-   NHPP, TPP models assume all lineages have the same preservation rate, but not all times have the same preservation rates (temporal heterogeneity, in different ways)

    -   All lineages have the same time-variable chance of being preserved in the fossil record

-   Gamma model assumes that preservation rates vary across both lineages and time (lineage AND temporal heterogeneity)

    -   Used in combo with NHPP, HPP, or TPP, allows each lineage to have its own time-variable preservation rate, taken from the gamma distribution

### 2.A.i. (NHPP) Non-Homogeneous Poisson Process of Preservation

PyRate's default model. NHPP models the preservation rate as a function of time Q(t), which means the preservation rate varies over time, following a specific bell-shaped distribution where rates are lower at the two ends (origin and extinction of the lineage, which is what happens in the fossil record anyway). The rate's temporal heterogeneity is a continuous function, and is not defined by discrete epochs. All lineages have this same rate.

**Terminal, feed your PyRate input file into PyRate:** `python PyRate.py *_PyRate.py`

### 2.A.ii. (HPP) Homogeneous Poisson Process

HPP is the simplest model. It assumes preservation rate (q) is constant throughout all of time: a single parameter. All lineages have the same rate.

**Terminal, specify the HPP model with the -mHPP flag:** `python PyRate.py *_PyRate.py -mHPP`

### 2.A.iii. (TPP) Time-Variable Poisson Process: **Rate Heterogeneity through Time**

In the TPP model, the preservation rate has temporal heterogeneity (can vary over time) just like the NHPP, BUT the way the rate varies is different:

TPP explicitly introduces the idea of discrete epochs. Each epoch has its own individual, constant/unchanging preservation rate, allowing for abrupt changes in the preservation process at specific time points. TPP will estimate each preservation rate (and its individual prior probability distribution, more on that below) in each epoch independently. So, basically it's a piecewise compilation of HPP likelihoods across multiple time periods, each with their own preservation rate.

Use this when you think rate heterogeneity is mostly occurring through time, not among lineages.

Firstly, you need to **create a .txt file** (below called epochs_q.txt) **defining your epochs.**

Then, in **Terminal, feed your PyRate input file and your .txt epochs file into PyRate, specifying python and TPP using the command `-qShift`**: `python PyRate.py *_PyRate.py -qShift path/to/epochs_q.txt`

So we have a preservation rates vector (the list of preservation rate occurring for each epoch we specified). The prior probability on that vector = a probability distribution PER preservation rate in each epoch = the probability distribution of that preservation rate occurring before considering the observed fossil occurrence data

Each epoch has its own preservation rate, with its own prior probability distribution. Here we model that prior probability distribution as a gamma distribution. Gamma distributions have 2 parameters allowing us to control what we think the probability of a fossil's preservation looked like: shape and rate.

Prior probability (P(A)) on a preservation rate = how likely it was that that fossil was preserved, before we take into account the fossil occurrence data. It is a distribution not a single value, one per preservation rate, one per epoch (since each epoch has its own individual preservation rate)

We need to set this prior probability distribution for each preservation rate. We model them each as their own gamma distribution w/ two parameters: shape and rate. The default is shape = 1.5 and rate = 1.5. This default prior assumes preservation rates are more likely to be concentrated around moderate values, with lower probability of extremely high or low rates.

-   Shape \> 1 = unimodal (single peak) distribution. Since default is 1.5, default assumes unimodal

-   Shape \< 1 = exponentially decreasing distribution

-   Rate = scaling the gamma distribution = variability in preservation rates = changing the mean and variance of the preservation rates

    -   Larger rate = distribution concentrated around smaller values

    -   Smaller rate = more spread out distribution

    -   1.5 is a moderate variability in preservation rates

Being able to change the gamma distribution means we have flexibility in modelling the shape/scale of prior probability.

Adding `-pP shape rate` to the end of that command is optional. The default prior on the vector of preservation rates is a single gamma distribution with shape parameter = 1.5 and rate parameter = 1.5. These values can be changed using the `-pP` command, e.g., `-pP 2 0.1`. The rate parameter of the prior can be estimated from the data by setting it to 0.

During the MCMC sampling process, PyRate explores different values for the preservation rates in each epoch, guided by the prior probability distributions. The posterior distribution of the preservation rates is then obtained by combining the prior probabilities with the likelihood of the observed fossil occurrence data.

By using a probability distribution as the prior for each preservation rate, PyRate allows for uncertainty and variability in the estimated rates across different epochs. The gamma distribution provides a flexible framework to express prior beliefs about the range and shape of the preservation rate distributions, while still allowing the data to inform the posterior estimates.

The model will output different preservation rates for each interval. These are known as the posterior probability (P(A\|B) = our model's updated belief about the preservation rates after we considered both

-   P(A) the prior probabilities (gamma distributions of the preservation rate in each epoch). How you set this obviously affects your posterior calculation, the ultimate output/goal of the model: P(A\|B)

-   and P(B\|A) the likelihood of observing the data (fossil occurrences)

In any anaysis with time bins, be careful that changes in diversification may be due to the change in preservation rate, not true biological signals

```{python}
# Variable to indicate whether TPP model is being used. == 1 means yes
TPP_model
```

### 2.A.iv. Gamma Model: q Rate Heterogeneity Among Lineages

TPP uses gamma distribution in preservation rate (q) priors. By adding the `-mG` flag do your analyses, the model will assume that the preservation rate follows a Gamma distribution, with each taxon getting assigned a preservation rate chosen from that distribution. Thus, each lineage can have it's own q rate.

This section describes how to distribute NHPP, HPP, and TPP lineage-specific preservation rates across a gamma distribution.

The Gamma model for lineage heterogeneity only adds a single parameter, which voids over-parameterization

Can be coupled with NHPP, HPP, TPP. In **Terminal, simply add this flag to the end of any of the model's run commands: -**`mG`

```{python}
argsG # variable in PyRate.py will indicate whether the Gamma model is being used

get_gamma_rates() # PyRate function calculates the Gamma-distributed rate heterogeneity across lineages

NHPP_lik(), HOMPP_lik(), TPP_model() # PyRate functions incorporate Gamma rate heterogeneity when calculating the likelihoods
```

### 2.A.v. Gamma + TPP –\> Saving Per-Lineage Relative Preservation Rates

If you're doing TPP Model + Gamma Model, you can **save off the estimated relative preservation rate for each lineage** with the following flag at the end of the TPP + Gamma run: `-log_sp_q_rates`

**Terminal:** `python PyRate.py *_PyRate.py *_PyRate.py -qShift epochs_q.txt -mG -log_sp_q_rates`

## 2.B. Preservation Models Testing (Maximum Likelihood Test)

**Terminal:** `python PyRate.py .../*_PyRate.py -qShift .../epochs_q.txt -PPmodeltest`

Does not test Gamma model, but you should take the best model among the NHPP, HPP or TPP outputted from this command, and add the Gamma to it

# 3. MCMC Analysis Setup: Generating pyrate_mcmc_logs Directory

So before we run the MCMC analysis, we chose a Preservation Model (conceptually, we haven't run it yet). In other tutorials we show how to choose a different Birth-Death Model. But in this tutorial we will use the default: Birth-Death Model with Rate Shifts. You don't have to indicate anything with this. Both MCMC options, BDMCMC or RJMCMC (default, better) use BDS as default.

Both BDMCMC and RJMCMC estimate the \# and timing/placement of rate shits (temporal rate heterogeneity).

**Terminal:** `python PyRate.py path/*_PyRate.py`

-   Arguments afterwards:

    -   No flag or `-A 4` for RJMCMC

    -   `-A 2` for BDMCMC

    -   Preservation model flag (\***Section 2.A.**):

        -   No flag to default to NHPP

        -   `-mHPP` for HPP

        -   `-qShift path/to/epochs_q.txt -pP shape rate` for TPP, where `-pP` is optional

        -   Gamma model flag `-mG`

    -   **Section 7**. If you want to set fixed time bins for the BD model (**BDC Skyline Model)**: do `-fixShift path/to/bd_epochs_q.txt`

        -   `bd_epochs_q.txt` can be the same or diff from the `epochs_q.txt` in the TPP (I.e., can be the same file if you want to use the same time bins for Preservation and S+E (Birth-Death)

    -   Specify which randomized replicate (**\*Section 1.A.**): `-j 1` flag, where the "1" in this case indicates the replicate number we want to analyze

    -   MCMC parameters:

        -   `-n 20000000` : do 20 million iterations or "steps" the MCMC algorithm will run (not 20 million states, depending on the acceptance/rejection rule). **Default is 10 million**! If the dataset is really large, Iterations may need to be increased in order to reach convergence

        -   `-s 5000`: sample every 5,000. **Default is 1,000**! If the dataset is really large, you may need to sample the chain less frequently (increase -s) to reduce the size of the ouput files

        -   **n/s = the \# of posterior samples the output log file will have.**

        -   So in this example, at 20 mill iterations, sampled every 5,000 –\> the output log file will have 4,000 posterior samples

        -   `-p 100` = the program will show its progress every 100 iterations

# 4. Output Files

Will be outputted automatically to a sub-folder called "pyrate_mcmc_logs"

All these file names will be **\*\_#\_Grj_sum.txt** (for example), with the \# corresponding to the \# replicate (if applicable), and the Grj indicating that RJMCMC was used

1.  **\*\_sum.txt:** text file with the list of settings used in the analysis
2.  **\*\_mcmc.log**: tab-separated table with MCMC samples of:
    1.  Preservation Model: posterior, prior, likelihood (PP_lik)
    2.  Birth-Death Model: posterior, prior, likelihood (BD_lik)
    3.  Preservation Rate (q_rate)
        1.  q_rate's level of heterogeneity: gamma-distributed heterogeneity (alpha)
        2.  (q_0, q_1, q_2...) if you used TPP model
    4.  \# of Sampled Rate Shifts (k_birth, k_death)
    5.  Origin time of the oldest lineage (root_age)
    6.  Total branch length (tot_length)
    7.  Times of S + E of all taxa/species in the dataset (\*\_TS*, \*\_*TE): I.e., origination and extinction times of each lineage
3.  **sp_rates.log:** tab-separated text file of sampled rates
4.  **ex_rates.log:** tab-separated text file of times of rate shifts
    1.  \^ Additional visualization commands can be added to a call of these log files, see the RJMCMC tutorial
5.  If you want to make **RTT plots (Section 5.C. or 5.F.**) you need to add the command `-log_marginal_rates 1` to get this older output file:
    1.  **\*\_marginal_rates.log**: tab-separated table with posterior samples of the marginal rates of
        1.  Speciation rate, extinction rate, net diversification. calculated w/in 1 time unit (typically Myr)
        2.  This file can be later processed using `-plot` (for RTT), but it cannot take `-plotRJ`

# 5. Results

Now you can interpret the S and E rates, the validity of different preservation models, and visualize temporal dynamics of diversification

## 5.A. MCMC Results: Tracer

Put all the outputted log files into Tracer, a program for analyzing the performance of the MCMC. Check if MCMC has converged, look at the ESS's, determine the proportion of burn-in.

Replicate datasets obviously might converge to slightly different solutions, with different ESS's

## 5.B. BD Model Sampling Frequencies (RJMCMC Only)

Take the \*\_**mcmc.log** output file and in **Terminal:** `python PyRate.py -mProb .../*_mcmc.log -b 200`

-   `-b #` flag: indicates how many beginning samples should be removed because in Tracer you decided that that \# was the burn-in

    -   Samples, not iterations. The number of samples you have will be = `-n`/`-s` flags from the analysis command in **\*Section 3**

**Output**: table with the relative probabilities of each BD model (each model is the same type, just with different number of rate shifts)

-   Obviously only RJMCMC analyzes different \#'s of rate shifts, so the table below would only work if you did the `-A 4` flag, or omitted the flag entirely in the MCMC analysis, because both indicate that you want to do an RJMCMC

-   If you chose `-A 2` for BDMCMC, `-mProb` would only show the posterior probability of the BD model, and possibly (??) some other parameter estimates. If you do

**Example Output** from tutorials/Canis_self_example/**:**

![mProb output in Terminal example](Canis_self_example/5.B._BD_Model_Sampling_Frequencies.png){width="400"}

1.  Model Probability:
    1.  Speciation has a 45.3% probability of having 1 rate shift
    2.  Extinction has a 0.01% probability of having 1 rate shift, and on
    3.  So: it is most probable that we have 1 rate shift in Speciation, and 2 rate shifts in Extinction
2.  Best BD/ID configurations:
    1.  Terminology: BD/ID are different lineage diversification models, considered to be identical in this table
        1.  BD = Birth-Death Model
        2.  ID = Immigration-Death Model
        3.  "B/I" basically corresponds to origination (birth or immigration) in the BD and ID models respectively
    2.  B/I Column = how many rate shifts in origination
    3.  D Column = how many rate shifts in death for both models
    4.  The most probable configuration is 32.5% probable, with 1 rate shift for speciation, 2 rate shifts for extinction

## 5.C. Rates-Through-Time (RTT) Plots

RTT plot: speciation, extinction, net diversification through time

Take the **\*marginal_rates.log** output file and in **Terminal:** `python PyRate.py -plot .../*_marginal_rates.log -b 200`

-   do `-plot2` instead of `-plot` for a different type of RTT

-   `-b` flag is the same as above

**Output**:

-   R script

-   PDF file with the RTT plots

## 5.D. Combining Replicates' \*\_mcmc.log files

You should already have a **directory** (folder) with all your output and Input files in it, indicated below as `path_to_your_log_files`

**Terminal:** `PyRate.py -combLog path_to_your_log_files -tag mcmc -b 100`

-   `-tag mcmc` specifies to PyRate that it should combine (`combLog`) all the files that contain `mcmc` in the file name. If you need to combine other files, just switch out the word that comes after `-tag`

-   `-b` flag is the same as above

**Output:**

-   **?**

## 5.E. Combining Replicates' \*\_marginal_rates.log files (for Combined RTT plot)

`PyRate.py -plot path_to_your_log_files -tag Canis_pbdb -b 100`

-   `-tag Canis_pbdb` : We used 'Canis_pbdb' as an example here. You should add part of the file name after the -tag so the command can combine all the **marginal_rates.log** files that contain that name

## 5.F. Plotting Preservation Rates Through Time (TPP)

TPP model has different rates for different time bins, and we'd like to view those:

`PyRate.py -plotQ .../*_mcmc.log -qShift epochs.txt -b 100`

-   **epochs.txt**: the text file with the times of rate shift you provided in **Section 2.A.iii.** May need full file path

# 6. BD Models with Fixed Rate Shifts

RJMCMC allows you to estimate timing and number of rate shifts using MCMC. If you want to fix those a priori though (based on external theory like geological epochs), you can do this by providing a file with pre-defined times of rate shifts, just like TPP took.

Remember that adding these time bins increases the model complexity, so you want to make sure you have sufficient data to support this complexity. Model assumes half-Cauchy prior distributions for speciation and extinction rates between shifts. Hyperprior on the half-Cauchy distribution's scale parameter, to reduce the risk of over-parameterization

`python PyRate.py .../*_PyRate.py -fixShift .../epochs.txt`

-   Follow up with all of your other arguments, Preservation model, length of the MCMC, sampling frequency

**Output:** the same 3 files as the previous analysis, but with these changes:

1.  **\*\_sum.txt**
2.  **\*\_mcmc.log**
    1.  ~~\# of Sampled Rate Shifts (k_birth, k_death)~~ –\> this \# is now fixed, so instead we will get:
        1.  Speciation rates between shifts (lambda_0, lambda_1...)
        2.  Extinction rates between shifts (mu_0, mu_1...)
    2.  Estimated scale parameter on the half-Cauchy distribution of speciation rates (hypL) and extinction rates (hypM)
3.  **\*\_marginal_rates.log**

# 7. Setting Fixed Shifts at the Boundaries, While Searching for Rate Shifts Between Them

Sometimes fossil data is only available during a certain time window, which means the min and max boundaries of that time window SEEM like they have rate shifts, when they actually don't (this is the edge effect, where the data at the edges of the time bin reflect a sampling bias).

You can fix this by setting fixed times of rate shifts at the edges of that time bin (`-edgeShift`), where you know the dataset is cut off. You're basicaly setting temporal boundaries so you can truncate your analysis to just the rates within that time window.

`python PyRate.py <data_set> -A 4 -edgeShift max min`

-   max = a NUMBER representing the maximum age boundary

    -   If you only want to set a maximum age boundary, just set min = `0`

-   min =